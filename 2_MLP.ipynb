{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab. 2 Multi Layered Networks\n",
    "\n",
    "### Ładowanie danych\n",
    "\n",
    "PyTroch, a właściwie pakiet `torchvision` udostępnia parę przydatnych rzeczy, z których skorzystamy na dzisiejszych zajęciach.\n",
    "\n",
    "Zacznijmy od ściąganie i ładowania danych, w [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html) znajdziemy popularne datasety, zajmiemy się dzisiaj MNISTem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: .\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision\n",
    "\n",
    "train_data = MNIST(root='.',\n",
    "                   download=True,\n",
    "                   transform=torchvision.transforms.ToTensor(),\n",
    "                   train=True)\n",
    "test_data = MNIST(root='.',\n",
    "                  download=True,\n",
    "                  transform=torchvision.transforms.ToTensor(),\n",
    "                  train=False)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oprócz tego z samego `torcha` możemy skorzystać z [`DataLoadera`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), który załatwia za nas sporo przydatnych rzeczy typu shufflowanie i batchowanie danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1307])\n",
      "tensor([0.3015])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=10)\n",
    "mean = 0\n",
    "std = 0\n",
    "for x, _ in train_loader:\n",
    "    batch_size = x.size(0)\n",
    "    batch_samples = x.view(batch_size, x.size(1), -1) \n",
    "    mean += batch_samples.mean(2).sum(0)\n",
    "    std += batch_samples.std(2).sum(0)\n",
    "    \n",
    "samples_num = len(train_loader.dataset)\n",
    "mean /= samples_num  \n",
    "std /= samples_num \n",
    "print(mean)\n",
    "print(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST(root='.',\n",
    "                   download=True,\n",
    "                   transform = torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize([mean], [std], inplace=False),\n",
    "                                   torchvision.transforms.Lambda(lambda x: x.flatten()),\n",
    "                               ]),\n",
    "                   train=True)\n",
    "test_data = MNIST(root='.',\n",
    "                  download=True,\n",
    "                   transform = torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                   torchvision.transforms.Normalize([mean], [std], inplace=False),\n",
    "                                   torchvision.transforms.Lambda(lambda x: x.flatten()),\n",
    "                   ]),\n",
    "                  train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=10)\n",
    "for x, _ in train_loader:\n",
    "    print(x.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wygląda na to, że aż tak bardzo za darmo wszystkiego nie dostaniemy, klasa `MNIST` zwraca nam dane w postaci obiektów [PILa](https://pillow.readthedocs.io/en/stable/). Musimy coś z tym zrobić.\n",
    "\n",
    "## Zadanie 1.\n",
    "1. Za pomocą [`transformerów`](https://pytorch.org/docs/stable/torchvision/transforms.html) przerobić powyższy kod tak aby zadziałał.  \n",
    "**HINT**: sprawdzić jakie argumenty przyjmuje klasa `MNIST`.\n",
    "2. Policzyć średnią i odchylenie standardowe wartości pojedynczego piksela dla całego zbioru trenującego i użyć ich do znormalizowania danych trenujących.  \n",
    "**HINT**: Tutaj torchvision też powinien nam to ułatwić.\n",
    "3. Zmienić \"kształt\" jednego przykładu z `28x28` na `784`.  \n",
    "**HINT**: [`Lambda`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Lambda)\n",
    "\n",
    "Uwaga: zwrócić uwagę co dokładnie robią używane _transformery_!\n",
    "\n",
    "## Zadanie 2.\n",
    "\n",
    "Ręcznie zaimplementować prostą sieć z jedną warstwą ukrtyą. Sieć ma mieć:\n",
    "1. Jedną warstwę ukrytą rozmiaru 500 z wagami zainicjalizowanymi ze standardowego rozkładu normalnego.\n",
    "2. Warstwa przy obu operacjach ma mieć uczone _biasy_ zainicjalizowane na 0.\n",
    "\n",
    "**HINT**: Do rozkładu normalnego najlepiej użyć [`torch.randn`](https://pytorch.org/docs/stable/torch.html#torch.randn). Sprawdzić jakie ważne argumenty ta funkcja przyjmuje!\n",
    "\n",
    "Należy oprócz tego zaimplementować pętlę uczenia z użyciem PyTorchowej funkcji kosztu _cross entropy_ i optymalizatora SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class CustomNetwork(object):\n",
    "    \"\"\"\n",
    "    Simple 1-hidden layer linear neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initialize network's weights \n",
    "        \"\"\"\n",
    "        \n",
    "        self.weight_1: torch.Tensor = torch.randn((input_size, hidden_size), requires_grad=True)\n",
    "        self.bias_1: torch.Tensor = torch.zeros((1, hidden_size), requires_grad=True) \n",
    "        \n",
    "        self.weight_2: torch.Tensor = torch.randn((hidden_size, output_size), requires_grad=True) \n",
    "        self.bias_2: torch.Tensor = torch.zeros((1, output_size), requires_grad=True) \n",
    "        \n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \"\"\"\n",
    "        output_1 = torch.mm(x, self.weight_1) + self.bias_1 \n",
    "        output_2 = torch.mm(output_1, self.weight_2) + self.bias_2 \n",
    "        \n",
    "        return output_2 \n",
    "    \n",
    "    def parameters(self) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns all trainable parameters \n",
    "        \"\"\"\n",
    "        return [self.weight_1, self.bias_1, self.weight_2, self.bias_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 iter 900/937 loss: 42.063056945800786\n",
      "Test accuracy: 0.842\n",
      "Epoch 1 iter 900/937 loss: 30.352207183837894\n",
      "Test accuracy: 0.8372\n",
      "Epoch 2 iter 900/937 loss: 15.188524246215824\n",
      "Test accuracy: 0.8439\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "# some hyperparams\n",
    "batch_size: int = 64\n",
    "epoch: int = 3\n",
    "lr: float = 0.01\n",
    "momentum: float = 0.9\n",
    "\n",
    "# prepare data loaders, base don the already loaded datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# initialize the model\n",
    "model: CustomNetwork = CustomNetwork(input_size=784,\n",
    "                                     hidden_size=500,\n",
    "                                     output_size=10) \n",
    "\n",
    "# initialize the optimizer\n",
    "optimizer: torch.optim.Optimizer = SGD(params=model.parameters(),\n",
    "                                       lr=lr,\n",
    "                                       momentum=momentum) \n",
    "\n",
    "# training loop\n",
    "for e in range(epoch):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        # reset the gradients from previouis iteration\n",
    "        optimizer.zero_grad()\n",
    "        # pass through the network\n",
    "        output: torch.Tensor = model(x) \n",
    "        # calculate loss\n",
    "        loss: torch.Tensor = torch.nn.CrossEntropyLoss()(output, y) \n",
    "        # backward pass thorught the network\n",
    "        loss.backward()\n",
    "        # apply the gradients\n",
    "        optimizer.step()\n",
    "        # log the loss value\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch {e} iter {i+1}/{len(train_data) // batch_size} loss: {loss.item()}\", end=\"\\r\")\n",
    "            \n",
    "    # at the end of an epoch run evaluation on the test set\n",
    "    with torch.no_grad():\n",
    "        # initialize the number of correct predictions\n",
    "        correct: int = 0 \n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            # pass through the network\n",
    "            output: torch.Tensor = model(x)\n",
    "            # update the number of correctly predicted examples\n",
    "            pred = output.max(1)[1]\n",
    "            correct += int(torch.sum(pred == y))\n",
    "\n",
    "        print(f\"\\nTest accuracy: {correct / len(test_data)}\")\n",
    "\n",
    "        \n",
    "# this is your test\n",
    "assert correct / len(test_data) > 0.8, \"Subject to random seed you should be able to get >80% accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3.\n",
    "\n",
    "1. Przepisać całą sieć do PyTorcha używając [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module), [`torch.nn.Linear`](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear).\n",
    "2. Dodać [nieliniowe aktywacje](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) i dodatkową warstwę, tak aby wyciągnąć przynajmniej 95% testowego accuracy w 3 epoki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class TorchNetwork(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple 2-hidden layer non-linear neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size,\n",
    "                 hidden_size_1,\n",
    "                 hidden_size_2,\n",
    "                 output_size):\n",
    "        super(TorchNetwork, self).__init__()\n",
    "        self.linear_layer_1 = nn.Linear(input_size, hidden_size_1)\n",
    "        self.activation_1 = nn.LeakyReLU(0.1)\n",
    "        self.linear_layer_2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.activation_2 = nn.LeakyReLU(0.1)\n",
    "        self.linear_layer_3 = nn.Linear(hidden_size_2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l_1 = self.linear_layer_1(x)\n",
    "        a_1 = self.activation_1(l_1)\n",
    "        l_2 = self.linear_layer_2(a_1)\n",
    "        a_2 = self.activation_2(l_2)\n",
    "        return a_2\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 iter 900/937 loss: 0.06492029130458832\n",
      "Test accuracy: 0.9402\n",
      "Epoch 1 iter 900/937 loss: 0.03403802216053009\n",
      "Test accuracy: 0.9617\n",
      "Epoch 2 iter 900/937 loss: 0.024125441908836365\n",
      "Test accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "# some hyperparams\n",
    "batch_size: int = 64\n",
    "epoch: int = 3\n",
    "lr: float = 0.01\n",
    "momentum: float = 0.9\n",
    "\n",
    "# prepare data loaders, base don the already loaded datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# initialize the model\n",
    "model: TorchNetwork = TorchNetwork(input_size=784,\n",
    "                                   hidden_size_1=500,  \n",
    "                                   hidden_size_2=100,\n",
    "                                   output_size=10\n",
    "                                   )  \n",
    "\n",
    "# initialize the optimizer\n",
    "optimizer: torch.optim.Optimizer = SGD(params=model.parameters(),\n",
    "                                       lr=lr,\n",
    "                                       momentum=momentum) \n",
    "\n",
    "\n",
    "# training loop\n",
    "for e in range(epoch):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        # reset the gradients from previouis iteration\n",
    "        optimizer.zero_grad()\n",
    "        # pass through the network\n",
    "        output: torch.Tensor = model(x) \n",
    "        # calculate loss\n",
    "        loss: torch.Tensor = torch.nn.CrossEntropyLoss()(output, y) \n",
    "        # backward pass thorught the network\n",
    "        loss.backward()\n",
    "        # apply the gradients\n",
    "        optimizer.step()\n",
    "        # log the loss value\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch {e} iter {i+1}/{len(train_data) // batch_size} loss: {loss.item()}\", end=\"\\r\")\n",
    "            \n",
    "    # at the end of an epoch run evaluation on the test set\n",
    "    with torch.no_grad():\n",
    "        # initialize the number of correct predictions\n",
    "        correct: int = 0 \n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            # pass through the network\n",
    "            output: torch.Tensor = model(x)\n",
    "            # update the number of correctly predicted examples\n",
    "            pred = output.max(1)[1]\n",
    "            correct += int(torch.sum(pred == y))\n",
    "\n",
    "        print(f\"\\nTest accuracy: {correct / len(test_data)}\")\n",
    "            \n",
    "            \n",
    "# this is your test       \n",
    "assert correct / len(test_data) > 0.95, \"Subject to random seed you should be able to get >95% accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
